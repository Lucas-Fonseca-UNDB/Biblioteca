# Guia Completo de Machine Learning
## Curso Estruturado da Teoria √† Pr√°tica em IA

---

## √çndice Geral

1. [M√≥dulo 1: Fundamentos de Machine Learning](#m√≥dulo-1-fundamentos-de-machine-learning)
2. [M√≥dulo 2: Matem√°tica e Estat√≠stica para ML](#m√≥dulo-2-matem√°tica-e-estat√≠stica-para-ml)
3. [M√≥dulo 3: Algoritmos Cl√°ssicos](#m√≥dulo-3-algoritmos-cl√°ssicos)
4. [M√≥dulo 4: Deep Learning](#m√≥dulo-4-deep-learning)
5. [M√≥dulo 5: Implementa√ß√£o Pr√°tica](#m√≥dulo-5-implementa√ß√£o-pr√°tica)
6. [M√≥dulo 6: Avalia√ß√£o e M√©tricas](#m√≥dulo-6-avalia√ß√£o-e-m√©tricas)
7. [M√≥dulo 7: Deploy e Produ√ß√£o](#m√≥dulo-7-deploy-e-produ√ß√£o)
8. [Extens√µes Avan√ßadas](#extens√µes-avan√ßadas)

---

# M√≥dulo 1: Fundamentos de Machine Learning

## 1.1 Defini√ß√£o e Hist√≥ria do ML

**Machine Learning** √© o campo de estudo que permite aos computadores aprenderem com dados sem serem explicitamente programados para cada tarefa (Arthur Samuel, 1959).

### Contexto Hist√≥rico

- **1943**: McCulloch e Pitts prop√µem o primeiro neur√¥nio artificial
- **1958**: Frank Rosenblatt inventa o Perceptron
- **1974-1980**: Primeiro "AI Winter" - limita√ß√µes computacionais
- **1980-1987**: Ressurgimento com sistemas especialistas
- **1987-1993**: Segundo "AI Winter"
- **1997**: Deep Blue derrota Kasparov em xadrez
- **2011-Presente**: Era do Deep Learning e Big Data
- **2017**: Vaswani et al. introduzem Transformers
- **2022+**: Modelos de linguagem de larga escala (LLMs)

### Defini√ß√£o Formal

Segundo Tom Mitchell (1997), um programa aprende com experi√™ncia **E** em rela√ß√£o a uma classe de tarefas **T** e medida de desempenho **P**, se seu desempenho em **T**, medido por **P**, melhora com a experi√™ncia **E**.

## 1.2 Tipos de Aprendizado

### Aprendizado Supervisionado

**Defini√ß√£o**: O modelo aprende com dados rotulados (features + labels).

**Tipos**:

1. **Classifica√ß√£o**: Predizer categorias discretas
   - Exemplo: Detec√ß√£o de spam (spam/n√£o-spam)
   - Sa√≠da: Categorias finitas

2. **Regress√£o**: Predizer valores cont√≠nuos
   - Exemplo: Pre√ßo de um im√≥vel
   - Sa√≠da: Valores num√©ricos cont√≠nuos

### Aprendizado N√£o-Supervisionado

**Defini√ß√£o**: O modelo encontra padr√µes em dados sem r√≥tulos.

**Tipos**:

1. **Clustering**: Agrupar dados similares
   - Exemplo: Segmenta√ß√£o de clientes
   - M√©todos: K-Means, DBSCAN, Hierarchical Clustering

2. **Redu√ß√£o de Dimensionalidade**: Reduzir n√∫mero de features
   - Exemplo: Visualiza√ß√£o de dados de alta dimens√£o
   - M√©todos: PCA, t-SNE, Autoencoders

3. **Detec√ß√£o de Anomalias**: Identificar outliers
   - Exemplo: Detec√ß√£o de fraude
   - M√©todos: Isolation Forest, Local Outlier Factor

### Aprendizado por Refor√ßo

**Defini√ß√£o**: Um agente aprende interagindo com um ambiente, recebendo recompensas/puni√ß√µes.

**Componentes**:
- **Agente**: Toma a√ß√µes
- **Ambiente**: Responde √†s a√ß√µes
- **Recompensa**: Sinal num√©rico de qualidade da a√ß√£o
- **Pol√≠tica**: Estrat√©gia do agente

**Aplica√ß√µes**: Jogos (AlphaGo), Rob√≥tica, Otimiza√ß√£o de recursos

### Aprendizado Semi-Supervisionado

**Defini√ß√£o**: Combina dados rotulados (pequeno) com n√£o-rotulados (grande).

**T√©cnicas**:
- Self-training
- Co-training
- Pseudo-labeling
- Expectation-Maximization (EM)

**Vantagem**: Reduz custo de anota√ß√£o manual

## 1.3 Paradigmas Principais

### Classifica√ß√£o

**Objetivo**: Predizer classe de uma amostra

**Tipos de Problemas**:
- **Bin√°ria**: 2 classes (sim/n√£o, positivo/negativo)
- **Multiclasse**: > 2 classes mutuamente exclusivas
- **Multilabel**: M√∫ltiplas labels por amostra

**Exemplo Matem√°tico**:

Dado um conjunto de dados \(\{(x_1, y_1), ..., (x_n, y_n)\}\) onde \(x_i \in \mathbb{R}^d\) e \(y_i \in \{1, 2, ..., K\}\), encontrar fun√ß√£o \(f: \mathbb{R}^d \rightarrow \{1, ..., K\}\) que minimize:

\[L = \frac{1}{n}\sum_{i=1}^{n} \mathcal{L}(f(x_i), y_i)\]

### Regress√£o

**Objetivo**: Predizer valor cont√≠nuo

**Exemplo Matem√°tico**:

Para dados \(\{(x_1, y_1), ..., (x_n, y_n)\}\) onde \(x_i \in \mathbb{R}^d\) e \(y_i \in \mathbb{R}\), encontrar \(f: \mathbb{R}^d \rightarrow \mathbb{R}\) que minimize erro quadr√°tico:

\[MSE = \frac{1}{n}\sum_{i=1}^{n} (y_i - f(x_i))^2\]

### Clustering

**Objetivo**: Agrupar dados similares sem r√≥tulos

**K-Means** exemplo:
- Particionar dados em K clusters
- Minimizar vari√¢ncia dentro de cada cluster
- Fun√ß√£o objetivo: \(J = \sum_{k=1}^{K} \sum_{x_i \in C_k} ||x_i - \mu_k||^2\)

### Redu√ß√£o de Dimensionalidade

**Objetivo**: Reduzir n√∫mero de features mantendo informa√ß√£o

**PCA** (Principal Component Analysis):
- Encontrar dire√ß√µes de m√°xima vari√¢ncia
- Projetar dados em subespa√ßo de menor dimens√£o
- Preserva estrutura essencial

## 1.4 Overfitting e Underfitting

### Defini√ß√µes

**Overfitting**: Modelo memoriza padr√µes espec√≠ficos do treinamento, generalizando mal em dados novos.

**Underfitting**: Modelo √© muito simples, n√£o captura padr√µes principais.

**Bias-Variance Tradeoff**: Balan√ßo entre vi√©s (underfitting) e vari√¢ncia (overfitting).

### An√°lise Matem√°tica

Erro total = Bias¬≤ + Vari√¢ncia + Erro Irreduz√≠vel

\[E[(f(x) - y)^2] = \text{Bias}^2[f(x)] + \text{Var}[f(x)] + \sigma^2\]

Onde:
- **Bias¬≤**: Erro esperado de um modelo simples
- **Vari√¢ncia**: Sensibilidade a flutua√ß√µes nos dados
- **œÉ¬≤**: Ru√≠do inerente aos dados

### Visualiza√ß√£o Conceitual

```
            Erro Total
                 |
         ___    /\    ___
        /   \  /  \  /
Erro  /      \/    \/
      |  Underfitting | Optimal | Overfitting |
      |     (High      |         |   (Low
      |      Bias)     |         |    Bias)
      ---------------------------------------->
               Complexidade do Modelo
```

### Estrat√©gias de Preven√ß√£o

1. **Valida√ß√£o Cruzada**: Avaliar em m√∫ltiplos subconjuntos
2. **Regulariza√ß√£o**: Penalizar complexidade (L1, L2)
3. **Early Stopping**: Parar treinamento quando val_loss aumenta
4. **Data Augmentation**: Aumentar dados de treinamento
5. **Dropout**: Desativar neur√¥nios aleatoriamente
6. **Redu√ß√£o de features**: Usar menos vari√°veis

---

# M√≥dulo 2: Matem√°tica e Estat√≠stica para ML

## 2.1 √Ålgebra Linear

### Conceitos Fundamentais

**Escalar**: N√∫mero √∫nico \(x \in \mathbb{R}\)

**Vetor**: Array de n√∫meros \(\mathbf{v} = [v_1, v_2, ..., v_n]^T \in \mathbb{R}^n\)

**Matriz**: Array 2D \(\mathbf{A} \in \mathbb{R}^{m \times n}\)

**Tensor**: Array n-dimensional (generaliza√ß√£o)

### Opera√ß√µes Essenciais

**Produto Escalar**:
\[\mathbf{u} \cdot \mathbf{v} = \sum_{i=1}^{n} u_i v_i = \mathbf{u}^T\mathbf{v}\]

**Norma (L2)**:
\[||\mathbf{v}||_2 = \sqrt{\sum_{i=1}^{n} v_i^2} = \sqrt{\mathbf{v}^T\mathbf{v}}\]

**Norma (L1)**:
\[||\mathbf{v}||_1 = \sum_{i=1}^{n} |v_i|\]

**Multiplica√ß√£o de Matrizes**:
\[(\mathbf{A}\mathbf{B})_{ij} = \sum_{k=1}^{p} A_{ik}B_{kj}\]

**Transposta**:
\[(\mathbf{A}^T)_{ij} = A_{ji}\]

**Propriedades Importantes**:
- \((\mathbf{A}\mathbf{B})^T = \mathbf{B}^T\mathbf{A}^T\)
- \((\mathbf{A}^{-1})^T = (\mathbf{A}^T)^{-1}\)

### Decomposi√ß√£o de Matrizes

**Determinante**: Mede invertibilidade e volume

\[\det(\mathbf{A}) = 0 \Rightarrow \mathbf{A} \text{ singular (n√£o invert√≠vel)}\]

**Eigenvalores e Eigenvectores**:

\[\mathbf{A}\mathbf{v} = \lambda \mathbf{v}\]

- \(\mathbf{v}\): eigenvector
- \(\lambda\): eigenvalue
- Encontrado resolvendo: \(\det(\mathbf{A} - \lambda\mathbf{I}) = 0\)

**Singular Value Decomposition (SVD)**:

\[\mathbf{A} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^T\]

- \(\mathbf{U}, \mathbf{V}\): matrizes ortogonais
- \(\mathbf{\Sigma}\): valores singulares (diagonais)
- Fundamental para: PCA, redu√ß√£o de dimensionalidade, compress√£o

## 2.2 C√°lculo e Otimiza√ß√£o

### Derivadas e Gradientes

**Derivada Parcial**:
\[\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1, ..., x_i + h, ..., x_n) - f(x_1, ..., x_n)}{h}\]

**Gradiente** (vetor de derivadas parciais):
\[\nabla f(\mathbf{x}) = \left[\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ..., \frac{\partial f}{\partial x_n}\right]^T\]

**Interpreta√ß√£o**: Aponta na dire√ß√£o de maior aumento

### Chain Rule

Para composi√ß√£o de fun√ß√µes \(z = f(g(\mathbf{x}))\):

\[\frac{\partial z}{\partial x_i} = \sum_j \frac{\partial f}{\partial g_j} \frac{\partial g_j}{\partial x_i}\]

**Forma Vetorial**:
\[\nabla_{\mathbf{x}} z = \left(\frac{\partial \mathbf{g}}{\partial \mathbf{x}}\right)^T \nabla_{\mathbf{g}} f\]

Fundamental para **backpropagation** em redes neurais.

### Otimiza√ß√£o: Gradient Descent

**Ideia**: Caminhar na dire√ß√£o oposta do gradiente

**Algoritmo**:
```
1. Inicializar w aleatoriamente
2. Para cada epoch:
   3. Calcular gradiente: ‚àáL(w)
   4. Atualizar: w := w - Œ∑‚àáL(w)
   5. Se convergeu: parar
```

Onde \(\eta\) √© a taxa de aprendizado (learning rate).

**Converg√™ncia**: Garante m√≠nimo local para fun√ß√µes convexas

### Varia√ß√µes do Gradient Descent

**Batch Gradient Descent** (BGD):
\[\mathbf{w} := \mathbf{w} - \eta \nabla L(\mathbf{w})\]
- Usa todos os dados (lento, mas est√°vel)

**Stochastic Gradient Descent** (SGD):
\[\mathbf{w} := \mathbf{w} - \eta \nabla L(\mathbf{w}; x_i, y_i)\]
- Usa 1 amostra por vez (r√°pido, ruidoso)

**Mini-batch Gradient Descent**:
\[\mathbf{w} := \mathbf{w} - \eta \frac{1}{B} \sum_{i \in B} \nabla L(\mathbf{w}; x_i, y_i)\]
- Usa B amostras (balan√ßo entre ambos)

**Momentum**:
\[\mathbf{v} := \beta \mathbf{v} - \eta \nabla L(\mathbf{w})\]
\[\mathbf{w} := \mathbf{w} + \mathbf{v}\]
- Acelera converg√™ncia com "in√©rcia"

**Adam** (Adaptive Moment Estimation):
\[\mathbf{m} := \beta_1 \mathbf{m} + (1-\beta_1)\nabla L\]
\[\mathbf{v} := \beta_2 \mathbf{v} + (1-\beta_2)(\nabla L)^2\]
\[\mathbf{w} := \mathbf{w} - \eta \frac{\mathbf{m}}{\sqrt{\mathbf{v}} + \epsilon}\]
- Adapta taxa para cada par√¢metro
- Mais eficiente em pr√°tica

## 2.3 Probabilidade e Estat√≠stica

### Distribui√ß√µes de Probabilidade

**Distribui√ß√£o Normal** (Gaussiana):

\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]

- \(\mu\): m√©dia
- \(\sigma^2\): vari√¢ncia
- Ub√≠qua em ML: muitas vari√°veis naturais s√£o gaussianas

**Distribui√ß√£o de Bernoulli**:

\[P(X=k) = p^k(1-p)^{1-k}, \quad k \in \{0,1\}\]

- Modela eventos bin√°rios
- Base para regress√£o log√≠stica

**Distribui√ß√£o Multinomial**:

\[P(X_1=k_1, ..., X_m=k_m) = \frac{n!}{k_1!...k_m!} p_1^{k_1}...p_m^{k_m}\]

- Generaliza Bernoulli para m√∫ltiplas categorias

### Teorema de Bayes

\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]

**Interpreta√ß√£o em ML**:
- \(P(A|B)\): Posterior (probabilidade do modelo dado dados)
- \(P(B|A)\): Likelihood (prob. dos dados dado modelo)
- \(P(A)\): Prior (cren√ßa antes de ver dados)
- \(P(B)\): Evidence (normalizador)

**Aplica√ß√£o**: Classifica√ß√£o Naive Bayes, Bayesian Inference

### Fun√ß√µes de Verossimilhan√ßa

**Likelihood** √© probabilidade dos dados observados dado par√¢metros:

\[\mathcal{L}(\theta | \mathbf{X}) = P(\mathbf{X} | \theta)\]

**Maximum Likelihood Estimation** (MLE):

\[\hat{\theta} = \arg\max_{\theta} \mathcal{L}(\theta | \mathbf{X})\]

**Exemplo - Regress√£o Linear**:

Assumir \(y_i \sim \mathcal{N}(\mathbf{w}^T\mathbf{x}_i, \sigma^2)\)

\[\mathcal{L} = \prod_{i=1}^{n} \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(y_i - \mathbf{w}^T\mathbf{x}_i)^2}{2\sigma^2}}\]

MLE leva a minimizar MSE (erro quadr√°tico m√©dio)

### Infer√™ncia Estat√≠stica

**Estimadores Pontuais**:
- **M√©dia Amostral**: \(\bar{x} = \frac{1}{n}\sum x_i\)
- **Vari√¢ncia Amostral**: \(s^2 = \frac{1}{n-1}\sum(x_i - \bar{x})^2\)

**Intervalos de Confian√ßa**:

Para m√©dia com desvio padr√£o desconhecido (t-student):

\[\bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}\]

**p-valor**: Probabilidade de observar resultado t√£o extremo sob hip√≥tese nula

---

# M√≥dulo 3: Algoritmos Cl√°ssicos

## 3.1 Regress√£o Linear e Log√≠stica

### Regress√£o Linear

**Modelo**:
\[\hat{y} = \mathbf{w}^T\mathbf{x} + b\]

**Objetivo**: Minimizar MSE

\[L = \frac{1}{n}\sum_{i=1}^{n}(y_i - (\mathbf{w}^T\mathbf{x}_i + b))^2\]

**Solu√ß√£o Anal√≠tica** (Normal Equation):

\[\mathbf{w} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}\]

**Vantagens**:
- Interpretabilidade (coeficientes t√™m significado)
- Computacionalmente eficiente
- Fundamenta√ß√£o te√≥rica s√≥lida

**Limita√ß√µes**:
- Assume rela√ß√£o linear
- Sens√≠vel a outliers
- Requer invers√£o de matriz (ineficiente para n >> d)

### Regress√£o Log√≠stica

**Modelo**: Para classifica√ß√£o bin√°ria

\[P(y=1|\mathbf{x}) = \sigma(\mathbf{w}^T\mathbf{x} + b) = \frac{1}{1 + e^{-(\mathbf{w}^T\mathbf{x} + b)}}\]

Onde \(\sigma\) √© a **fun√ß√£o sigmoid**.

**Fun√ß√£o de Perda** (Cross-Entropy):

\[L = -\frac{1}{n}\sum_{i=1}^{n}[y_i\log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]\]

**Otimiza√ß√£o**: Via gradient descent (n√£o tem solu√ß√£o anal√≠tica)

**Extens√£o Multiclasse** (Softmax):

\[P(y=k|\mathbf{x}) = \frac{e^{\mathbf{w}_k^T\mathbf{x}}}{\sum_{j=1}^{K}e^{\mathbf{w}_j^T\mathbf{x}}}\]

## 3.2 √Årvores de Decis√£o e Random Forest

### √Årvores de Decis√£o

**Conceito**: Particionar espa√ßo de features recursivamente

**Algoritmo ID3/C4.5**:
1. Selecionar feature que melhor divide dados (m√°xima informa√ß√£o)
2. Criar branch para cada valor
3. Recursivamente repetir para subconjuntos
4. Parar quando classe √© pura ou crit√©rio √© atendido

**Crit√©rio de Divis√£o - Entropy**:

\[H(S) = -\sum_{c} p_c \log_2(p_c)\]

**Information Gain**:

\[IG = H(\text{parent}) - \sum \frac{|S_i|}{|S|} H(S_i)\]

**Vantagens**:
- Interpretabilidade visual
- Captura n√£o-linearidades
- Sem normaliza√ß√£o necess√°ria

**Limita√ß√µes**:
- Tend√™ncia a overfitting
- Inst√°vel (pequenas mudan√ßas causam grandes mudan√ßas)

### Random Forest

**Ideia**: Ensemble de m√∫ltiplas √°rvores, cada uma em subset aleat√≥rio

**Algoritmo**:
1. Para b = 1 at√© B:
   - Amostrar B' amostras com reposi√ß√£o (bootstrap)
   - Treinar √°rvore T_b em B' com feature subset aleat√≥rio
2. Predi√ß√£o final: M√©dia (regress√£o) ou Vota√ß√£o (classifica√ß√£o)

**Matem√°tica Formal**:

\[\hat{y} = \frac{1}{B} \sum_{b=1}^{B} T_b(\mathbf{x})\]

**Vantagens sobre √°rvore √∫nica**:
- Reduz vari√¢ncia via averaging
- Decorrela√ß√£o entre √°rvores (random subsets)
- Paraleliz√°vel
- Feature importance estim√°vel

**Import√¢ncia de Feature**:

\[Imp(f) = \frac{1}{B}\sum_{b=1}^{B} \sum_{t \in T_b} \mathbb{1}(\text{split em } f) \cdot \Delta IG_t\]

## 3.3 Support Vector Machines (SVM)

**Conceito**: Encontrar hiperplano √≥timo que maximize margem entre classes

### SVM Linear

**Objetivo**:

Maximizar margem = \(\frac{2}{||\mathbf{w}||}\) sujeito a:

\[y_i(\mathbf{w}^T\mathbf{x}_i + b) \geq 1, \quad \forall i\]

**Formula√ß√£o Dual**:

\[\max_{\alpha} \sum_i \alpha_i - \frac{1}{2}\sum_{i,j} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^T\mathbf{x}_j\]

Sujeito a: \(0 \leq \alpha_i \leq C\) e \(\sum_i \alpha_i y_i = 0\)

Onde \(\alpha_i\) s√£o multiplicadores de Lagrange e C controla regulariza√ß√£o.

### SVM com Kernel

**Ideia**: Mapear para espa√ßo de maior dimensionalidade onde dados s√£o linearmente separ√°veis

**Truque do Kernel**: 

\[\mathbf{x}_i^T\mathbf{x}_j \Rightarrow K(\mathbf{x}_i, \mathbf{x}_j)\]

Sem calcular mapeamento expl√≠cito!

**Kernels Comuns**:

- Linear: \(K(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i^T\mathbf{x}_j\)
- Polinomial: \(K(\mathbf{x}_i, \mathbf{x}_j) = (\gamma \mathbf{x}_i^T\mathbf{x}_j + r)^d\)
- RBF (Gaussian): \(K(\mathbf{x}_i, \mathbf{x}_j) = e^{-\gamma||\mathbf{x}_i - \mathbf{x}_j||^2}\)

## 3.4 K-Nearest Neighbors (KNN)

**Princ√≠pio**: "Diga-me seus vizinhos e direi quem voc√™ √©"

**Algoritmo**:
1. Dado novo ponto \(\mathbf{x}\)
2. Encontrar K vizinhos mais pr√≥ximos no conjunto treinamento
3. Classifica√ß√£o: Vota√ß√£o entre K vizinhos
4. Regress√£o: M√©dia dos K vizinhos

**Predi√ß√£o**:

\[\hat{y}(\mathbf{x}) = \frac{1}{K}\sum_{i \in \text{K-NN}} y_i\]

**M√©trica de Dist√¢ncia** (padr√£o - Euclidiana):

\[d(\mathbf{x}_i, \mathbf{x}_j) = \sqrt{\sum_{d=1}^{D} (x_{id} - x_{jd})^2}\]

**Vantagens**:
- Extremamente simples
- Sem fase de treinamento (lazy learner)
- Funciona bem com dados n√£o-lineares

**Limita√ß√µes**:
- Computacionalmente caro em predi√ß√£o (O(n))
- Sens√≠vel a features n√£o-normalizadas
- "Curse of dimensionality": espa√ßo fica esparso em altas dimens√µes

## 3.5 Naive Bayes

**Assun√ß√£o Fundamental**: Features s√£o condicionalmente independentes dado a classe

\[P(\mathbf{x}|y) = \prod_{d=1}^{D} P(x_d|y)\]

**Classificador**:

\[\hat{y} = \arg\max_y P(y) \prod_{d=1}^{D} P(x_d|y)\]

**Estima√ß√£o de Probabilidades**:

\[P(x_d|y) = \frac{\text{count}(x_d, y)}{\text{count}(y)}\]

Com suaviza√ß√£o Laplace para evitar zeros:

\[P(x_d|y) = \frac{\text{count}(x_d, y) + 1}{\text{count}(y) + K}\]

Onde K √© n√∫mero de categorias.

**Variantes**:
- Multinomial Naive Bayes: Contagem de palavras (NLP)
- Gaussian Naive Bayes: Assume distribui√ß√£o normal
- Bernoulli Naive Bayes: Features bin√°rias

**Vantagens**:
- Muito r√°pido
- Funciona bem em alta dimens√£o (NLP)
- Poucos dados necess√°rios

**Limita√ß√µes**:
- Assun√ß√£o de independ√™ncia frequentemente violada

## 3.6 Clustering

### K-Means

**Objetivo**: Particionar dados em K clusters minimizando vari√¢ncia

**Algoritmo**:
1. Inicializar K centroides aleatoriamente
2. Atribuir cada ponto ao centroide mais pr√≥ximo
3. Atualizar centroides como m√©dia dos pontos
4. Repetir 2-3 at√© converg√™ncia

**Fun√ß√£o Objetivo**:

\[J = \sum_{k=1}^{K} \sum_{\mathbf{x} \in C_k} ||\mathbf{x} - \mu_k||^2\]

Onde \(\mu_k\) √© centroide do cluster k.

**Complexidade**: O(nkd) por itera√ß√£o

**Limita√ß√µes**:
- Requer K pr√©-definido
- Sens√≠vel a inicializa√ß√£o
- Assume clusters esf√©ricos

### DBSCAN

**Abordagem Baseada em Densidade**: Clusters s√£o regi√µes de alta densidade separadas por baixa densidade

**Par√¢metros**:
- \(\epsilon\): Raio de vizinhan√ßa
- \(MinPts\): N√∫mero m√≠nimo de pontos em vizinhan√ßa

**Defini√ß√µes**:
- **Core Point**: Tem ‚â• MinPts pontos em raio Œµ
- **Border Point**: N√£o √© core mas pr√≥ximo de core
- **Outlier**: Nem core nem border

**Vantagens**:
- Descobre n√∫mero de clusters automaticamente
- Identifica outliers
- Clusters de forma arbitr√°ria

**Limita√ß√£o**: Sens√≠vel a escolha de Œµ e MinPts

### Hierarchical Clustering

**Ideia**: Construir hierarquia de clusters (dendrograma)

**Aglomerativo** (bottom-up):
1. Come√ßar com cada ponto como cluster
2. Repetidamente mesclar 2 clusters mais pr√≥ximos
3. Parar quando crit√©rio √© atendido

**Linkage Criteria**:
- Complete: M√°xima dist√¢ncia entre clusters
- Single: M√≠nima dist√¢ncia (encadeia)
- Average: Dist√¢ncia m√©dia
- Ward: Minimiza vari√¢ncia (similar a K-Means)

**Vantagem**: Hierarquia oferece flexibilidade de granularidade

---

# M√≥dulo 4: Deep Learning

## 4.1 Redes Neurais: Fundamentos

### Neur√¥nio Artificial (Perceptron)

**Modelo**:

\[a = \sigma\left(\sum_{i} w_i x_i + b\right) = \sigma(\mathbf{w}^T\mathbf{x} + b)\]

Onde:
- \(\mathbf{x}\): inputs
- \(\mathbf{w}\): weights
- \(b\): bias
- \(\sigma\): fun√ß√£o de ativa√ß√£o

**Neur√¥nio Original** (McCulloch-Pitts):

\[y = \begin{cases} 1 & \text{se } \sum_i w_i x_i + b > 0 \\ 0 & \text{caso contr√°rio} \end{cases}\]

Fun√ß√£o step n√£o diferenci√°vel ‚Üí Problema para treinamento!

### Fun√ß√µes de Ativa√ß√£o

**Sigmoid**:

\[\sigma(z) = \frac{1}{1 + e^{-z}}\]

- Sa√≠da em (0,1)
- Derivada: \(\sigma'(z) = \sigma(z)(1-\sigma(z))\)
- Problema: Vanishing gradients em extremos

**Tanh**:

\[\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\]

- Sa√≠da em (-1,1)
- Centrada em 0 (melhor que sigmoid)
- Mesma problema de vanishing gradients

**ReLU** (Rectified Linear Unit):

\[\text{ReLU}(z) = \max(0, z)\]

- Simples e eficiente computacionalmente
- Derivada: 1 se z > 0, 0 caso contr√°rio
- Problema: Dead ReLU (neur√¥nios que nunca ativam)

**Leaky ReLU**:

\[\text{Leaky ReLU}(z) = \begin{cases} z & \text{if } z > 0 \\ \alpha z & \text{case contr√°rio} \end{cases}\]

Onde \(\alpha\) √© pequeno (0.01)

**ELU** (Exponential Linear Unit):

\[\text{ELU}(z) = \begin{cases} z & \text{if } z > 0 \\ \alpha(e^z - 1) & \text{case contr√°rio} \end{cases}\]

**GELU** (Gaussian Error Linear Unit):

\[\text{GELU}(z) = z \cdot \Phi(z)\]

Onde \(\Phi\) √© CDF da distribui√ß√£o normal. Usado em Transformers modernos.

## 4.2 Backpropagation

**Conceito**: Calcular gradientes eficientemente via chain rule

**Rede Simples**:

\[z^{(l)} = \mathbf{w}^{(l)} a^{(l-1)} + b^{(l)}\]
\[a^{(l)} = \sigma(z^{(l)})\]

**Loss**:

\[L = \frac{1}{n}\sum_i ||a^{(L)}(\mathbf{x}_i) - y_i||^2\]

Onde L √© √∫ltima camada.

**Algoritmo Backpropagation**:

1. **Forward Pass**: Calcular \(a^{(l)}\) para todas camadas
2. **Backward Pass**: Calcular gradientes de tr√°s para frente
   - \(\frac{\partial L}{\partial a^{(L)}} = 2(a^{(L)} - y)\)
   - \(\frac{\partial L}{\partial w^{(l)}} = \frac{\partial L}{\partial z^{(l)}} \cdot (a^{(l-1)})^T\)
   - \(\frac{\partial L}{\partial a^{(l-1)}} = (\mathbf{w}^{(l)})^T \frac{\partial L}{\partial z^{(l)}}\)

3. **Atualizar Pesos**:
   \[\mathbf{w}^{(l)} := \mathbf{w}^{(l)} - \eta \frac{\partial L}{\partial w^{(l)}}\]

**Complexidade**: O(n par√¢metros) para calcular todos gradientes (eficiente!)

## 4.3 Arquiteturas de Redes Neurais

### MLP (Multi-Layer Perceptron)

**Estrutura**: Sequ√™ncia de camadas densas

```
Input (d) ‚Üí Hidden (h1) ‚Üí Hidden (h2) ‚Üí Output (k)
```

**Universalidade**: Uma rede com 1 camada oculta pode aproximar qualquer fun√ß√£o cont√≠nua (teorema de aproxima√ß√£o universal).

**Pr√°tica**: M√∫ltiplas camadas geralmente melhor (diferentes n√≠veis de abstra√ß√£o).

### CNN (Convolutional Neural Network)

**Motiva√ß√£o**: Capturar estrutura espacial em dados (imagens)

**Opera√ß√£o Convolu√ß√£o**:

\[y[i,j] = \sum_{u,v} w[u,v] \cdot x[i+u, j+v]\]

Onde \(w\) √© kernel pequeno (ex: 3√ó3).

**Vantagens**:
- Compartilha pesos (reduz par√¢metros)
- Preserva estrutura espacial
- Detecta features hier√°rquicas

**Arquitetura T√≠pica**:
```
Input ‚Üí Conv ‚Üí ReLU ‚Üí MaxPool ‚Üí Conv ‚Üí ReLU ‚Üí MaxPool ‚Üí FC ‚Üí Output
```

**Pooling** (ex: Max Pooling):

\[y = \max(x[2i:2i+2, 2j:2j+2])\]

- Reduz dimens√£o
- Captura feature mais saliente
- Provides translation invariance

### RNN (Recurrent Neural Network)

**Conceito**: Processar sequ√™ncias com mem√≥ria

**Equa√ß√£o Recorrente**:

\[h_t = \sigma(w^{(h)} h_{t-1} + w^{(x)} x_t + b)\]
\[y_t = w^{(o)} h_t + b^{(o)}\]

Onde \(h_t\) √© estado oculto (mem√≥ria).

**Problema**: Vanishing Gradient
- Gradientes decaem exponencialmente ao longo do tempo
- RNNs profundas n√£o aprendem depend√™ncias de longo prazo

### LSTM (Long Short-Term Memory)

**Solu√ß√£o** ao vanishing gradient: Mecanismo de "cell state" com gates

**Componentes**:

1. **Forget Gate**: Decide o que esquecer
   \[f_t = \sigma(w^{(f)} [h_{t-1}, x_t] + b^{(f)})\]

2. **Input Gate**: Decide o que adicionar
   \[i_t = \sigma(w^{(i)} [h_{t-1}, x_t] + b^{(i)})\]
   \[\tilde{c}_t = \tanh(w^{(c)} [h_{t-1}, x_t] + b^{(c)})\]

3. **Cell State** (mem√≥ria de longo prazo):
   \[c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t\]

4. **Output Gate**:
   \[o_t = \sigma(w^{(o)} [h_{t-1}, x_t] + b^{(o)})\]
   \[h_t = o_t \odot \tanh(c_t)\]

Onde \(\odot\) √© multiplica√ß√£o element-wise.

**Vantagem**: Cell state flui linearmente (cadeia aditiva), permitindo gradientes longos

### GRU (Gated Recurrent Unit)

**Vers√£o Simplificada** do LSTM:

\[r_t = \sigma(w^{(r)}[h_{t-1}, x_t])\]
\[\tilde{h}_t = \tanh(w^{(h)}[r_t \odot h_{t-1}, x_t])\]
\[h_t = (1-r_t) \odot h_{t-1} + r_t \odot \tilde{h}_t\]

- Menos par√¢metros que LSTM
- Performance similar em muitas tarefas
- Mais f√°cil de treinar

### Transformers e Attention

**Inova√ß√£o Principal**: Aten√ß√£o (Vaswani et al., 2017)

**Self-Attention**:

\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\]

Onde:
- \(Q, K, V\): Query, Key, Value (proje√ß√µes de input)
- \(d_k\): Dimens√£o de Key
- Cada posi√ß√£o atende todas outras posi√ß√µes em paralelo

**Multi-Head Attention**:

\[\text{MultiHead}(Q,K,V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O\]

Onde cada head calcula self-attention independentemente.

**Transformer Block**:
1. Multi-head self-attention
2. Feed-forward (2 camadas densas com ReLU)
3. Residual connections: output = input + sublayer(input)
4. Layer normalization

**Vantagens**:
- Paraleliz√°vel (ao contr√°rio de RNNs)
- Captura depend√™ncias de longo prazo
- Escal√°vel para sequ√™ncias muito longas

**Sucesso**: Base de GPT, BERT, LLMs modernos

## 4.4 Regulariza√ß√£o em Deep Learning

### Dropout

**Ideia**: Desativar aleatoriamente fra√ß√£o de neur√¥nios durante treinamento

**Algoritmo**:
```
Durante treinamento:
  Para cada neur√¥nio: Com prob p, output = 0
  
Durante teste:
  Sem dropout, mas escalar outputs por (1-p)
```

**Efeito**: For√ßa rede a aprender representa√ß√µes redundantes, reduzindo co-adapta√ß√£o

**Dropout Rate**: T√≠pico 0.2-0.5

### Batch Normalization

**Problema**: Mudan√ßas em pesos causam mudan√ßas em distribui√ß√£o de ativa√ß√µes (internal covariate shift)

**Solu√ß√£o**: Normalizar ativa√ß√µes por batch

\[\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}\]

\[y = \gamma \hat{x} + \beta\]

Onde:
- \(\mu_B, \sigma_B\): M√©dia e vari√¢ncia do batch
- \(\gamma, \beta\): Par√¢metros aprend√≠veis (scale e shift)

**Benef√≠cios**:
- Permite learning rates maiores
- Reduz depend√™ncia de inicializa√ß√£o
- Efeito regularizador

### Early Stopping

**Monitorar** validation loss durante treinamento:

```
Se validation_loss n√£o melhora por N epochs:
  Salvar modelo do melhor epoch
  Parar treinamento
```

**Previne** overfitting automaticamente

### Regulariza√ß√£o L1 e L2

**L2** (Ridge):
\[L_{total} = L + \frac{\lambda}{2n} ||\mathbf{w}||_2^2\]

- Penaliza pesos grandes
- Favorece pesos pequenos mas n√£o-zero

**L1** (Lasso):
\[L_{total} = L + \frac{\lambda}{n} ||\mathbf{w}||_1\]

- Pode for√ßar alguns pesos a zero
- Feature selection impl√≠cita

### Weight Decay em Adam e Otimizadores

```
w := w - lr * (m_hat / sqrt(v_hat + eps)) - lambda * w
```

Decaimento de peso desacoplado melhora desempenho.

## 4.5 Transfer Learning e Fine-tuning

**Conceito**: Usar modelo treinado em dataset grande, adaptar para tarefa nova

**Estrat√©gias**:

1. **Feature Extraction**: Congelar pesos de camadas anteriores, treinar √∫ltimas camadas
   ```
   Modelo pr√©-treinado (frozen) ‚Üí New FC Layer ‚Üí Train nova camada
   ```

2. **Fine-tuning**: Descongelar todas camadas, treinar com learning rate muito pequeno
   ```
   Modelo pr√©-treinado ‚Üí Ajustar todos pesos com lr baixa
   ```

**Quando usar**:
- Poucos dados dispon√≠veis
- Tarefa relacionada ao modelo pr√©-treinado
- Recursos computacionais limitados

**Modelos Populares Pr√©-treinados**:
- ImageNet: ResNet, VGG, EfficientNet
- NLP: BERT, GPT, T5

---

# M√≥dulo 5: Implementa√ß√£o Pr√°tica

## 5.1 Pipeline de ML Completo

### 1. Coleta e Explora√ß√£o de Dados

**Processo**:
1. Coletar dados de m√∫ltiplas fontes
2. Explora√ß√£o estat√≠stica descritiva
3. Visualiza√ß√µes (histogramas, scatter plots, correla√ß√£o)
4. Identificar missings, outliers, desbalanceamento

**Exemplo Python** (vide arquivo ML-Codigo-Pronto.md):

```python
import pandas as pd
import numpy as np

# Carregar dados
df = pd.read_csv('data.csv')

# Explora√ß√£o b√°sica
print(df.head())
print(df.info())
print(df.describe())
print(df.isnull().sum())

# Correla√ß√£o
correlation = df.corr()
```

### 2. Limpeza de Dados

**Tarefas**:
- Remover/imputar dados faltantes
- Tratar outliers (remover ou transformar)
- Corrigir inconsist√™ncias

**Imputa√ß√£o**:

```python
from sklearn.impute import SimpleImputer, KNNImputer

# Estrat√©gia simples
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# K-NN mais sofisticado
knn_imputer = KNNImputer(n_neighbors=5)
X_imputed = knn_imputer.fit_transform(X)
```

### 3. Feature Engineering

**Cria√ß√£o de Features**:
- Intera√ß√µes entre features
- Transforma√ß√µes polinomiais
- Extrair features de texto/data

**Sele√ß√£o de Features**:
- Remover features altamente correlacionadas
- M√©todos baseados em import√¢ncia
- RFE (Recursive Feature Elimination)

```python
from sklearn.feature_selection import RFE, SelectKBest, f_classif

# RFE
rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10)
X_selected = rfe.fit_transform(X, y)

# SelectKBest
selector = SelectKBest(score_func=f_classif, k=10)
X_selected = selector.fit_transform(X, y)
```

### 4. Normaliza√ß√£o e Scaling

**Por que Normalizar**:
- Algoritmos como SVM, KNN usam dist√¢ncia
- Gradient descent converge mais r√°pido
- Regulariza√ß√£o funciona melhor

**T√©cnicas**:

**StandardScaler** (Z-score):
\[\tilde{x} = \frac{x - \mu}{\sigma}\]

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # Usar stats de treino!
```

**MinMaxScaler** (Normaliza√ß√£o [0,1]):
\[\tilde{x} = \frac{x - x_{min}}{x_{max} - x_{min}}\]

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))
```

**RobustScaler** (Robusto a outliers):

Usa mediana e IQR (interquartile range)

### 5. Divis√£o Treino-Valida√ß√£o-Teste

```python
from sklearn.model_selection import train_test_split

# Estrat√©gia 1: 70-15-15
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)

# Melhor: Usar StratifiedKFold para desbalanceamento
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
for train_idx, val_idx in skf.split(X, y):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
```

### 6. Treinamento de Modelo

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predi√ß√µes
y_train_pred = model.predict(X_train)
y_val_pred = model.predict(X_val)
```

## 5.2 Cross-Validation e Hyperparameter Tuning

### K-Fold Cross-Validation

**Princ√≠pio**: Treinar K vezes, cada vez usando diferente fold como valida√ß√£o

```python
from sklearn.model_selection import cross_val_score

# Avaliar modelo com 5-fold CV
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f'CV Scores: {scores}')
print(f'Mean: {scores.mean():.3f} (+/- {scores.std():.3f})')
```

**Visualiza√ß√£o**:
```
Fold 1: Train [2,3,4,5] | Val [1]
Fold 2: Train [1,3,4,5] | Val [2]
Fold 3: Train [1,2,4,5] | Val [3]
Fold 4: Train [1,2,3,5] | Val [4]
Fold 5: Train [1,2,3,4] | Val [5]
```

### Grid Search

**Busca Exaustiva** em grid de hiperpar√¢metros

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    RandomForestClassifier(),
    param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1  # Use todos cores
)

grid_search.fit(X_train, y_train)
print(f'Best params: {grid_search.best_params_}')
print(f'Best score: {grid_search.best_score_:.3f}')

# Usar melhor modelo
best_model = grid_search.best_estimator_
```

### Random Search

**Menos Computacionalmente Caro** que Grid Search

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_dist = {
    'n_estimators': randint(50, 300),
    'max_depth': [10, 20, 30, None],
    'min_samples_split': randint(2, 20)
}

random_search = RandomizedSearchCV(
    RandomForestClassifier(),
    param_dist,
    n_iter=20,
    cv=5,
    n_jobs=-1
)

random_search.fit(X_train, y_train)
```

### Optuna: Otimiza√ß√£o Bayesiana

```python
import optuna

def objective(trial):
    # Sugerir hiperpar√¢metros
    n_estimators = trial.suggest_int('n_estimators', 50, 300)
    max_depth = trial.suggest_int('max_depth', 10, 50)
    
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
    
    # Avaliar com CV
    score = cross_val_score(model, X_train, y_train, cv=5).mean()
    return score

# Otimizar
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

print(f'Best params: {study.best_params}')
print(f'Best score: {study.best_value}')
```

## 5.3 Versionamento e Reprodutibilidade

### Seed para Reprodutibilidade

```python
import numpy as np
import tensorflow as tf
from sklearn.utils import check_random_state

def set_seeds(seed):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seeds(42)
```

### MLflow para Versionamento

```python
import mlflow
from mlflow import log_metric, log_params, log_model

mlflow.start_run(run_name="rf_experiment")

# Log par√¢metros
mlflow.log_params({
    'n_estimators': 100,
    'max_depth': 20,
    'model_type': 'RandomForest'
})

# Log m√©tricas
mlflow.log_metric('train_accuracy', train_acc)
mlflow.log_metric('val_accuracy', val_acc)

# Log modelo
mlflow.sklearn.log_model(model, 'model')

mlflow.end_run()
```

### DVC (Data Version Control)

```bash
# Inicializar DVC
dvc init

# Rastrear dados/modelos
dvc add data/raw/train.csv
dvc add models/model.pkl

# Reproducir pipeline
dvc repro
```

---

# M√≥dulo 6: Avalia√ß√£o e M√©tricas

## 6.1 M√©tricas de Classifica√ß√£o

### Matriz de Confus√£o

Para classifica√ß√£o bin√°ria:

```
                Predito
              Positivo  Negativo
Real Positivo    TP       FN
     Negativo     FP       TN
```

Onde:
- TP (True Positive): Predito positivo, √© positivo
- FN (False Negative): Predito negativo, √© positivo
- FP (False Positive): Predito positivo, √© negativo
- TN (True Negative): Predito negativo, √© negativo

```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
```

### Accuracy (Acur√°cia)

\[\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}\]

- M√©trica geral
- **Problema**: Desbalanceamento de classes (ex: 99% negativos)

### Precision (Precis√£o)

\[\text{Precision} = \frac{TP}{TP + FP}\]

- De **todos positivos preditos**, quantos s√£o realmente positivos?
- M√©trica de "Confian√ßa nas predi√ß√µes positivas"
- Importante quando FP √© custoso

### Recall (Sensibilidade/Cobertura)

\[\text{Recall} = \frac{TP}{TP + FN}\]

- De **todos positivos reais**, quantos foram detectados?
- M√©trica de "N√£o deixar passar positivos"
- Importante quando FN √© custoso (ex: diagn√≥stico)

### F1-Score

\[\text{F1} = 2 \cdot \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\]

- M√©dia harm√¥nica de Precision e Recall
- Usa quando classes desbalanceadas

### ROC-AUC

**ROC Curve** (Receiver Operating Characteristic):

- Eixo X: False Positive Rate = \(\frac{FP}{FP+TN}\)
- Eixo Y: True Positive Rate = Recall = \(\frac{TP}{TP+FN}\)

**AUC** (Area Under Curve):

- √Årea sob a curva ROC
- Interpreta√ß√£o: Probabilidade modelo classifica positivo aleat√≥rio melhor que negativo aleat√≥rio
- 1.0 = Perfeito, 0.5 = Aleat√≥rio

```python
from sklearn.metrics import roc_curve, auc, roc_auc_score

fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)
auc_score = auc(fpr, tpr)

# Plotar
plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
```

### Macroaverage vs Microaverage

Para multiclasse:

**Macroaverage**: Calcular m√©trica para cada classe, depois m√©dia

\[\text{Macro-F1} = \frac{1}{K}\sum_{i=1}^{K} F1_i\]

- Trata todas classes igualmente

**Microaverage**: Calcular contribui√ß√µes globais

\[\text{Micro-F1} = F1(\sum TP_i, \sum FP_i, \sum FN_i)\]

- Ponderado pelo n√∫mero de amostras por classe

```python
from sklearn.metrics import f1_score

macro_f1 = f1_score(y_true, y_pred, average='macro')
micro_f1 = f1_score(y_true, y_pred, average='micro')
```

## 6.2 M√©tricas de Regress√£o

### Mean Squared Error (MSE)

\[\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2\]

- Penaliza erros grandes (quadr√°tico)
- Mesmas unidades elevadas ao quadrado

### Root Mean Squared Error (RMSE)

\[\text{RMSE} = \sqrt{\text{MSE}}\]

- Mesmas unidades que target
- Interpret√°vel como "erro m√©dio"

### Mean Absolute Error (MAE)

\[\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|\]

- Linear (menos penaliza outliers que MSE)
- Mais robusto

### R¬≤ Score

\[R^2 = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}\]

- Propor√ß√£o de vari√¢ncia explicada
- 1.0 = Perfeito, 0.0 = Modelo=m√©dia, <0 = Pior que m√©dia

```python
from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_true, y_pred)
```

### MAPE (Mean Absolute Percentage Error)

\[\text{MAPE} = \frac{1}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right| \times 100\]

- Erro em percentual
- Interpret√°vel comercialmente
- Problema: Indefinido se y_i = 0

## 6.3 M√©tricas de Clustering

### Silhouette Score

Mede qu√£o bem cada ponto se encaixa em seu cluster comparado a outros clusters.

\[s_i = \frac{b_i - a_i}{\max(a_i, b_i)}\]

Onde:
- \(a_i\): Dist√¢ncia m√©dia para outros pontos no mesmo cluster
- \(b_i\): Dist√¢ncia m√©dia para pontos no cluster mais pr√≥ximo

\[\text{Silhouette} = \frac{1}{n}\sum_i s_i\]

- Intervalo: [-1, 1]
- 1 = √ìtimo, 0 = Sobreposto, -1 = Ruim

```python
from sklearn.metrics import silhouette_score

score = silhouette_score(X, labels)
```

### Davies-Bouldin Index

Raz√£o m√©dia de dispers√£o de cada cluster com seu mais pr√≥ximo.

\[\text{DB} = \frac{1}{K}\sum_{i=1}^{K} \max_{j \neq i} \frac{S_i + S_j}{d_{ij}}\]

- Menores valores = Melhor (0 = √ìtimo)

### Calinski-Harabasz Score

Raz√£o entre vari√¢ncia entre-clusters e intra-cluster.

\[\text{CH} = \frac{B/(K-1)}{W/(n-K)}\]

- Maiores valores = Melhor

```python
from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score

db = davies_bouldin_score(X, labels)
ch = calinski_harabasz_score(X, labels)
```

## 6.4 Valida√ß√£o Cruzada

### Estratifica√ß√£o

Para dados desbalanceados, usar StratifiedKFold:

```python
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, val_idx in skf.split(X, y):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
    # Treinar e validar
```

Garante distribui√ß√£o de classes preservada em cada fold.

### Time Series Split

Para dados temporais:

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

for train_idx, val_idx in tscv.split(X):
    X_train, X_val = X[train_idx], X[val_idx]
    # train_idx sempre antes de val_idx (respeita ordem temporal)
```

---

# M√≥dulo 7: Deploy e Produ√ß√£o

## 7.1 MLOps: CI/CD para Modelos

**MLOps** integra ML com DevOps:

1. **Data Pipeline**: Coleta, limpeza, valida√ß√£o
2. **Training Pipeline**: Treinamento, versionamento
3. **Model Registry**: Armazenar modelos
4. **Monitoring**: Detectar drift, performance
5. **Retraining**: Autom√°tico quando drift

### Exemplo: GitHub Actions + MLflow

```yaml
name: ML Pipeline

on: [push]

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Train model
        run: python train.py
      - name: Test model
        run: python test.py
      - name: Log to MLflow
        run: python log_model.py
```

## 7.2 Servindo Modelos: FastAPI

**FastAPI** para APIs REST de alta performance:

```python
from fastapi import FastAPI
from pydantic import BaseModel
import pickle
import numpy as np

app = FastAPI()

# Carregar modelo
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

class InputData(BaseModel):
    features: list[float]

class Prediction(BaseModel):
    prediction: float
    probability: float

@app.post("/predict")
async def predict(data: InputData):
    X = np.array(data.features).reshape(1, -1)
    pred = model.predict(X)[0]
    proba = model.predict_proba(X)[0]
    
    return Prediction(
        prediction=int(pred),
        probability=float(max(proba))
    )

@app.get("/health")
async def health():
    return {"status": "ok"}
```

**Executar**:
```bash
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

### Flask (Alternativa Mais Simples)

```python
from flask import Flask, request, jsonify
import pickle

app = Flask(__name__)

with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json['features']
    X = np.array(data).reshape(1, -1)
    pred = model.predict(X)[0]
    return jsonify({'prediction': int(pred)})

if __name__ == '__main__':
    app.run(debug=True)
```

## 7.3 Monitoramento em Produ√ß√£o

### Drift Detection

**Data Drift**: Distribui√ß√£o de features muda

```python
from scipy.stats import ks_2samp

def detect_drift(X_train, X_new, threshold=0.05):
    p_values = []
    for i in range(X_train.shape[1]):
        stat, p_value = ks_2samp(X_train[:, i], X_new[:, i])
        p_values.append(p_value)
    
    n_drifts = sum(1 for p in p_values if p < threshold)
    return n_drifts, p_values

n_drifts, p_vals = detect_drift(X_train, X_new_batch)
if n_drifts > threshold_features:
    alert("Data drift detected! Retrain model")
```

**Concept Drift**: Rela√ß√£o entre X e y muda

```python
# Monitorar performance em produ√ß√£o
def check_concept_drift(y_true, y_pred, window_size=1000):
    if len(y_true) >= window_size:
        recent_acc = accuracy_score(
            y_true[-window_size:],
            y_pred[-window_size:]
        )
        if recent_acc < threshold:
            return True  # Concept drift detected
    return False
```

### Performance Tracking

```python
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

def log_prediction(features, prediction, confidence, timestamp=None):
    timestamp = timestamp or datetime.now()
    logger.info(f"Pred={prediction}, Conf={confidence}, Time={timestamp}")
    
    # Armazenar em DB para an√°lise posterior
    db.insert({
        'features': features,
        'prediction': prediction,
        'confidence': confidence,
        'timestamp': timestamp
    })
```

## 7.4 Escalabilidade e Otimiza√ß√£o

### Quantiza√ß√£o

Reduzir precis√£o (float32 ‚Üí float16 ou int8) para infer√™ncia mais r√°pida:

```python
import tensorflow as tf

# Quantiza√ß√£o para TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_saved_model("model")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quantized_model = converter.convert()

with open('model_quantized.tflite', 'wb') as f:
    f.write(tflite_quantized_model)
```

### Batch Inference

Processar m√∫ltiplas predi√ß√µes eficientemente:

```python
def batch_predict(model, data, batch_size=32):
    predictions = []
    for i in range(0, len(data), batch_size):
        batch = data[i:i+batch_size]
        preds = model.predict(batch)
        predictions.extend(preds)
    return np.array(predictions)
```

### Caching

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=10000)
def predict_cached(features_hash):
    # Evitar predizer mesmos inputs m√∫ltiplas vezes
    return model.predict(decode_features(features_hash))

def get_prediction(features):
    features_hash = hashlib.md5(str(features).encode()).hexdigest()
    return predict_cached(features_hash)
```

### Containeriza√ß√£o (Docker)

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
# Build
docker build -t ml-api .

# Run
docker run -p 8000:8000 ml-api
```

---

# Extens√µes Avan√ßadas

## Ensemble Methods

### Bagging (Bootstrap Aggregating)

**Princ√≠pio**: Treinar m√∫ltiplos modelos em amostras com reposi√ß√£o, combinar predi√ß√µes

**Algoritmo**:
1. Para b = 1 at√© B:
   - Amostrar com reposi√ß√£o dataset original
   - Treinar modelo M_b nessa amostra
2. Predi√ß√£o final: M√©dia (regress√£o) ou Vota√ß√£o (classifica√ß√£o)

**Reduz Vari√¢ncia**: Variance reduzida por fator 1/B (aproximadamente)

### Boosting

**Princ√≠pio**: Treinar modelos sequencialmente, cada focando em exemplos que anteriores erraram

**Adaboost**:

```
1. Inicializar pesos uniformes w_i = 1/n
2. Para t = 1 at√© T:
   a. Treinar fraco learner h_t em dados ponderados
   b. Calcular erro: Œµ_t = Œ£ w_i ùïÄ(h_t(x_i) ‚â† y_i)
   c. Peso do modelo: Œ±_t = 0.5 * ln((1-Œµ_t)/Œµ_t)
   d. Atualizar pesos: w_i := w_i * exp(-Œ±_t * y_i * h_t(x_i))
   e. Normalizar pesos
3. Predi√ß√£o final: sign(Œ£ Œ±_t * h_t(x))
```

**Gradient Boosting** (XGBoost, LightGBM):

```
1. f_0(x) = valor inicial (ex: m√©dia de y)
2. Para t = 1 at√© T:
   a. Calcular residuais: r_i = y_i - f_{t-1}(x_i)
   b. Treinar √°rvore h_t para predizer r_i
   c. f_t(x) = f_{t-1}(x) + ŒΩ * h_t(x)  [ŒΩ √© learning rate]
3. Predi√ß√£o final: f_T(x)
```

**Vantagem**: Reduz Bias e Vari√¢ncia sequencialmente

## AutoML e Neural Architecture Search

**AutoML**: Automatizar sele√ß√£o de algoritmo, features, hiperpar√¢metros

### Auto-sklearn

```python
from autosklearn.classification import AutoSklearnClassifier

automl = AutoSklearnClassifier(
    time_left_for_this_task=3600,  # 1 hora
    per_run_time_limit=60
)

automl.fit(X_train, y_train)
print(automl.show_models())
predictions = automl.predict(X_test)
```

### AutoKeras

```python
import autokeras as ak

# Classifica√ß√£o com redes neurais autom√°ticas
clf = ak.ImageClassifier(max_trials=10)
clf.fit(X_train, y_train)
predictions = clf.predict(X_test)
```

### NAS (Neural Architecture Search)

Busca espa√ßo de arquiteturas neurais automaticamente usando:
- Reinforcement Learning
- Evolutionary Algorithms
- Bayesian Optimization

## Federated Learning

**Conceito**: Treinar modelos sem centralizar dados (privacidade)

**Algoritmo FedAvg**:

```
1. Servidor inicializa pesos w_0
2. Para round t:
   a. Servidor envia w_t para K clientes
   b. Cada cliente k:
      - Baixa w_t
      - Treina em seus dados locais: w_k,t = w_t - Œ∑‚àáL_k(w_t)
   c. Servidor agrega: w_{t+1} = (1/K) Œ£ w_k,t
```

**Aplica√ß√£o**: Modelos de teclado em smartphones, an√°lise m√©dica com privacidade

## Explicabilidade de Modelos

### SHAP (SHapley Additive exPlanations)

Baseia-se em teoria dos jogos (Shapley values)

```python
import shap

# Explicar predi√ß√µes de modelo
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# Visualizar
shap.summary_plot(shap_values, X)
shap.dependence_plot("feature_name", shap_values, X)
```

**Interpreta√ß√£o**: Quanto cada feature contribui para mudan√ßa de predi√ß√£o vs baseline

### LIME (Local Interpretable Model-agnostic Explanations)

Aproximar modelo complexo localmente com modelo interpret√°vel

```python
import lime
import lime.lime_tabular

explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=class_names
)

exp = explainer.explain_instance(X_test[0], model.predict_proba)
exp.show_in_notebook()
```

### Integrated Gradients

Atribui import√¢ncia calculando gradientes ao longo caminho de baseline para input

\[\text{IG}_i(x) = (x_i - x'_i) \int_0^1 \frac{\partial f(x' + \alpha(x-x'))}{\partial x_i} d\alpha\]

---

## Refer√™ncias Fundamentais

### Livros Cl√°ssicos

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*. Springer.

### Papers Seminais

- Vaswani, A., et al. (2017). "Attention Is All You Need" - Transformers
- LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). "Gradient-based learning applied to document recognition" - CNNs
- Hochreiter, S., & Schmidhuber, J. (1997). "Long Short-Term Memory" - LSTM
- Breiman, L. (2001). "Random Forests" - Random Forest

### Datasets Populares

- **MNIST**: D√≠gitos escritos √† m√£o
- **CIFAR-10/100**: Imagens 32√ó32
- **ImageNet**: 1.2M imagens, 1000 classes
- **IMDB**: Reviews de filmes
- **UCI ML Repository**: Datasets variados

### Bibliotecas Essenciais

- **scikit-learn**: Algoritmos cl√°ssicos
- **TensorFlow/Keras**: Deep Learning
- **PyTorch**: Deep Learning flex√≠vel
- **pandas**: Data manipulation
- **numpy**: Computa√ß√£o num√©rica
- **matplotlib/seaborn**: Visualiza√ß√£o
- **XGBoost/LightGBM**: Gradient Boosting
- **MLflow**: Versionamento

---

**Conclus√£o**: Este guia fornece funda√ß√µes s√≥lidas te√≥ricas e pr√°ticas para dominar Machine Learning. O caminho para expertise envolve estudo cont√≠nuo, experimenta√ß√£o com dados reais e implementa√ß√£o de projetos complexos.
